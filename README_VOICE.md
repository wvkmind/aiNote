#  语音识别功能

AI 笔记系统现已支持实时流式语音识别！

##  功能特性

-  **实时流式识别** - 说话时即时显示识别结果
-  **智能文本插入** - 自动插入到光标位置或 AI 聊天框
-  **美观的 UI** - 蓝色渐变气泡，脉动动画效果
-  **离线识别** - 基于本地 FunASR 模型，无需联网
-  **高性能** - 实时识别延迟仅 3 秒

##  STT 语音服务

语音识别功能需要单独运行 STT 服务：

**GitHub 仓库**: https://github.com/wvkmind/stt

### 推荐使用：
- `server_cpp.py` - C++ 加速版本（推荐，速度更快）
- `server_onnx.py` - ONNX 版本（兼容性更好）

### 快速启动：

```bash
# 克隆 STT 服务
git clone https://github.com/wvkmind/stt.git
cd stt

# 安装依赖
pip install -r requirements.txt

# 启动服务（推荐）
python server_cpp.py

# 或使用 ONNX 版本
python server_onnx.py
```

服务将在 `ws://localhost:8765` 启动。

##  效果预览

```

 识别中: 这是一段测试语音...          实时识别气泡
 (脉动动画)                      

              
        [  ]  麦克风按钮
```

##  使用步骤

### 1. 启动语音服务

```bash
cd stt
python server_cpp.py  # 或 server_onnx.py
```

### 2. 启动应用

```bash
npm run tauri dev
```

### 3. 使用语音输入

1. 点击右下角的蓝色麦克风按钮 
2. 开始说话，实时识别结果会显示在气泡中
3. 再次点击停止录音
4. 最终识别结果自动插入到编辑器

##  智能插入

语音识别结果会智能插入到：

-  **编辑器光标位置** - 如果焦点在编辑器中
-  **AI 聊天输入框** - 如果焦点在聊天框中
-  **编辑器末尾** - 如果没有焦点

##  技术栈

- **语音识别**: FunASR (paraformer-zh)
- **实时通信**: WebSocket
- **音频处理**: ffmpeg
- **后端服务**: FastAPI + Uvicorn
- **前端组件**: React + TypeScript

##  性能指标

| 指标 | 数值 |
|------|------|
| 实时识别延迟 | ~3秒 |
| 最终识别延迟 | ~2秒 |
| 模型大小 | ~900MB |
| 内存占用 | ~2GB |
| 识别准确率 | >95% (清晰语音) |

##  配置要求

### 最低配置
- CPU: 双核 2.0GHz
- 内存: 4GB RAM
- 磁盘: 4GB 可用空间

### 推荐配置
- CPU: 四核 2.5GHz+
- 内存: 8GB RAM
- 磁盘: 10GB 可用空间
- 麦克风: 外置麦克风（更好的识别效果）

##  常见问题

### Q: 麦克风无法使用

**A:** 检查系统权限设置，确保应用已获得麦克风权限。

### Q: 识别不准确

**A:**
- 使用外置麦克风
- 说话清晰，避免环境噪音
- 确保麦克风距离适中（15-30cm）

### Q: 服务连接失败

**A:**
- 确保语音服务已启动
- 检查端口 8765 是否被占用
- 查看服务日志排查错误

### Q: 识别速度慢

**A:**
- 关闭其他占用 CPU 的程序
- 使用 GPU 加速（需要 NVIDIA 显卡）
- 考虑升级硬件配置

##  相关文档

- [STT 服务仓库](https://github.com/wvkmind/stt)
- [Windows 安装指南](./VOICE_SETUP_GUIDE.md)
- [完整文档](./README.md)

##  更新日志

### v1.0.0 (2024-11-11)

-  首次发布语音识别功能
-  实现实时流式识别
-  智能文本插入
-  支持 Windows 和 macOS
-  完整的文档和指南

##  贡献

欢迎提交 Issue 和 Pull Request！

##  许可证

MIT License

---

**享受语音输入带来的便捷体验！** 
